# TensorFlow Lite Object Detection App for Visually Impaired Users

## Overview

This Android application leverages TensorFlow Lite for real-time object detection using the device camera. The primary goal is to assist visually impaired users by providing auditory feedback about the detected objects' location â€“ whether they are on the left or right side. This enhances the user's spatial awareness and helps them navigate their surroundings more effectively.

## Features

- **TensorFlow Lite Object Detection:** Utilizes a pre-trained machine learning model for accurate and efficient object detection.
- **Spatial Localization:** Announces the location of detected objects, specifying whether they are on the left or right side of the user.
- **User-Friendly Interface:** Designed with accessibility in mind, ensuring a seamless experience for visually impaired users.
- **Real-Time Feedback:** Delivers instant spoken feedback to enhance the user's awareness.

## Requirements

- Android device with a camera
- Internet connection (for initial setup and potential model updates)

## Installation

1. Clone the repository to your local machine:

   ```bash
   git clone https://github.com/swatinain/object-detection-app.git
   ```
2. Open the project in Android Studio.
3. Ensure that the required dependencies are installed and configured.
4. Build and run the application on your Android device.

## Usage
1. Launch the app and grant necessary permissions.
2. Point the device camera towards objects of interest.
3. Experience real-time object detection and receive spoken feedback about the location of detected objects.

## License
This project is licensed under the MIT License.